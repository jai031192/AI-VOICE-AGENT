# ЁЯУБ chatbot_logic.py
from langgraph.graph import StateGraph, END
from typing import TypedDict, List, Dict
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import google.generativeai as genai
import numpy as np
import json

# Define chatbot state
class ChatbotState(TypedDict):
    user_input: str
    history: List[Dict[str, str]]
    response: str
    knowledge_base: List[str]
    is_first_message: bool
    retrieved_context: List[str]

# Load and flatten knowledge base
with open("wheels_eye_conversations.json", "r", encoding="utf-8") as f:
    kb_raw = json.load(f)
flattened_kb = [msg.get("text") or msg.get("message") for convo in kb_raw["conversations"] for msg in convo["messages"] if msg.get("text") or msg.get("message")]

# Gemini setup
genai.configure(api_key="AIzaSyBMadNj9xk2AxinNTqnzDbC3EIO_j5i8rE")
model = genai.GenerativeModel("gemini-2.5-flash")

# Embedding model
embedding_model = SentenceTransformer("all-MiniLM-L6-v2")

# Nodes

def initial_node(state: ChatbotState) -> ChatbotState:
    if state["is_first_message"]:
        greeting = "рдирдорд╕реНрддреЗ рд╕рд░, рдореИрдВ рд░рд╡рд┐ рдмреЛрд▓ рд░рд╣рд╛ рд╣реВрдБ WheelsEye рд╕реЗ тАФ рдЖрдкрдХреА рдЧрд╛рдбрд╝реА рд▓реЛрдб рд╡рд╛рд▓реА рд╣реИ рдХреНрдпрд╛?"
        state["response"] = greeting
        state["history"].append({"role": "rep", "text": greeting})
        state["is_first_message"] = False
    return state

def retrieve_node(state: ChatbotState) -> ChatbotState:
    if not state["user_input"]:
        return state
    query_embedding = embedding_model.encode(state["user_input"])
    kb_embeddings = embedding_model.encode(state["knowledge_base"])
    scores = cosine_similarity([query_embedding], kb_embeddings)[0]
    top_indices = np.argsort(scores)[-3:][::-1]
    context = [state["knowledge_base"][i] for i in top_indices if scores[i] > 0.3]
    state["retrieved_context"] = context
    return state

def generate_node(state: ChatbotState) -> ChatbotState:
    context_text = "\n".join(state.get("retrieved_context", []))
    history_text = "\n".join([f'{x["role"]}: {x["text"]}' for x in state["history"]])
    prompt = f"""
рддреБрдо WheelsEye рдХрдВрдкрдиреА рдХреЗ рд╕реЗрд▓реНрд╕ рдкреНрд░рддрд┐рдирд┐рдзрд┐ рд╣реЛ (рдирд╛рдо рд░рд╡рд┐)ред
рддреБрдореНрд╣рд╛рд░рд╛ рдХрд╛рдо рд╣реИ рдлреНрд▓реАрдЯ рдСрдкрд░реЗрдЯрд░ рд╕реЗ рдЬрд╝рд░реВрд░реА рдЬрд╛рдирдХрд╛рд░реА рд▓реЗрдирд╛ рдФрд░ рдЙрд╕реЗ рд╕рдордЭрд╛рдирд╛ рдХрд┐ Wheelseye рд╕реЗ рдЬреБрдбрд╝рдиреЗ рдкрд░ рдЙрд╕реЗ рдХреНрдпрд╛ рдлрд╝рд╛рдпрджрд╛ рд╣реЛрдЧрд╛ тАФ рд╡реЛ рднреА рд░реЛрдЬрд╝рдорд░реНрд░рд╛ рдХреА, рд╕рд╛рдлрд╝-рд╕реБрдерд░реА рдФрд░ рд╢рд╛рд▓реАрди рд╣рд┐рдВрджреА рдореЗрдВред

 рддреБрдореНрд╣реЗрдВ рдЗрди рдмрд╛рддреЛрдВ рдХреА рдЬрд╛рдирдХрд╛рд░реА рд▓реЗрдиреА рд╣реИ:
рдЧрд╛рдбрд╝реА рд▓реЛрдбрд┐рдВрдЧ рд╡рд╛рд▓реА рд╣реИ?

рдХрд╣рд╛рдБ рд╕реЗ рд▓реЛрдб рд▓реЗрддреЗ рд╣реИрдВ?

рдХрдореАрд╢рди рджреЗрдирд╛ рдкрдбрд╝рддрд╛ рд╣реИ рдХреНрдпрд╛?

рд░реВрдЯ рдФрд░ рдЧрд╛рдбрд╝реА рдХреА рдбрд┐рдЯреЗрд▓ рдХреНрдпрд╛ рд╣реИ?

рдЧрд╛рдбрд╝реА рдХрд╛ рдирд╛рдк рдХреНрдпрд╛ рд╣реИ?

рдХреМрди-рд╕реА рдЯрд╛рдЗрдк рдХреА рдЧрд╛рдбрд╝реА рд╣реИ?

рдЧрд╛рдбрд╝реА рдХрд┐рддрдиреЗ рдЯрди рдХреА рд╣реИ?

рдХрд┐рддрдиреЗ рдЯрд╛рдпрд░ рдХреА рдЧрд╛рдбрд╝реА рд╣реИ?

рдХреБрд▓ рдХрд┐рддрдиреА рдЧрд╛рдбрд╝рд┐рдпрд╛рдБ рд╣реИрдВ?

 рддреБрдореНрд╣реЗрдВ рдЗрди рдлрд╝рд╛рдпрджреЛрдВ рдХреЛ рд╕рд╣реА рд╕рдордп рдкрд░ рдмрд╛рддрдЪреАрдд рдореЗрдВ рд╢рд╛рдорд┐рд▓ рдХрд░рдирд╛ рд╣реИ:
(рдЬрдм рдмрд╛рдд рдмрди рд░рд╣реА рд╣реЛ тАФ рдФрд░ рдЗрдВрд╕рд╛рди рдХреА рддрд░рд╣ рд╕рдордЭрд╛рдУ рдХрд┐ рдЗрд╕рд╕реЗ рдЙрд╕реЗ рдлрд╛рдпрджрд╛ рдХреИрд╕реЗ рд╣реЛрдЧрд╛)

рдмрд┐рдирд╛ рдХрд┐рд╕реА рдХрдореАрд╢рди рдХреЗ рд▓реЛрдб рдорд┐рд▓реЗрдЧрд╛

рдкреЗрдореЗрдВрдЯ 90% рдПрдбрд╡рд╛рдВрд╕ рдореЗрдВ рд╣реЛрдЧрд╛

рдХреЛрдИ рд▓реЗрдмрд░ рдЪрд╛рд░реНрдЬ рдпрд╛ рджрд╛рд▓рд╛ рдЪрд╛рд░реНрдЬ рдирд╣реАрдВ рд▓рдЧреЗрдЧрд╛

Wheelseye рд╕реЗ рдЬреБрдбрд╝рдиреЗ рдкрд░ рд▓реЛрдб рдвреВрдБрдврдиреЗ рдХрд╛ рдЭрдВрдЭрдЯ рдирд╣реАрдВ рд░рд╣реЗрдЧрд╛

рдЬрд┐рддрдирд╛ рдХрд╛рдо, рдЙрддрдиреА рдХрдорд╛рдИ тАФ рд╕рдм рдХреБрдЫ рд╕реАрдзрд╛ рдФрд░ рдкрд╛рд░рджрд░реНрд╢реА рд╣реЛрдЧрд╛

 рдмрд╛рдд рдХрд░рддреЗ рд╕рдордп рдЗрди рдмрд╛рддреЛрдВ рдХрд╛ рдзреНрдпрд╛рди рд░рдЦрдирд╛ рд╣реИ:
рд╕рд┐рд░реНрдл рдкреНрд░рддрд┐рдирд┐рдзрд┐ рдХреА рднреВрдорд┐рдХрд╛ рдирд┐рднрд╛рдУ тАФ рдЧреНрд░рд╛рд╣рдХ рдХреЗ рдЬрд╡рд╛рдм рдХреА рд╡реНрдпрд╛рдЦреНрдпрд╛ рдпрд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдордд рдХрд░реЛ

рдХреЛрдИ рд╡реИрдХрд▓реНрдкрд┐рдХ рдЙрддреНрддрд░ рдпрд╛ рд╕реБрдЭрд╛рд╡ рдордд рджреЛ

рд╣рд░ рдмрд╛рд░ рд╕рд┐рд░реНрдл рдПрдХ рд▓рд╛рдЗрди рдореЗрдВ рдмрд╛рдд рдкреВрд░реА рдХрд░рдиреЗ рдХреА рдХреЛрд╢рд┐рд╢ рдХрд░реЛ, рд▓реЗрдХрд┐рди рдЬрд╝рд░реВрд░рдд рдкрдбрд╝реЗ рддреЛ рд╢рд╛рдВрдд, рд╕рд╣рдЬ рдврдВрдЧ рд╕реЗ рдмрд╛рдд рд╕рдордЭрд╛рдирд╛ рднреА рдареАрдХ рд╣реИ

рд▓рд╣рдЬрд╛ рджреЛрд╕реНрддрд╛рдирд╛ рд╣реЛ, рд▓реЗрдХрд┐рди рдкреНрд░реЛрдлреЗрд╢рдирд▓

рдЬрдм рдСрдкрд░реЗрдЯрд░ рдХреЛрдИ рдЬрд╛рдирдХрд╛рд░реА рджреЗ, рддреЛ рдЙрд╕рдореЗрдВ рд╕реЗ 1-2 рдкреЙрдЗрдВрдЯ рджреЛрд╣рд░рд╛рдХрд░ рдХрдиреНрдлрд░реНрдо рдЬрд╝рд░реВрд░ рдХрд░реЛ (рдЬреИрд╕реЗ: "рддреЛ рдорддрд▓рдм рдЖрдкрдХреА рдЧрд╛рдбрд╝рд┐рдпрд╛рдБ 14 рдЯрди рдХреА рд╣реИрдВ рдФрд░ рд░реВрдЯ рджрд┐рд▓реНрд▓реА рд╕реЗ рд╣рд░рд┐рджреНрд╡рд╛рд░ рд╣реИ?")

рдЬрд╣рд╛рдВ рдЬрд╝рд░реВрд░рдд рд╣реЛ, рдлрд╝рд╛рдпрджреЗ рдЫреЛрдЯреЗ-рдЫреЛрдЯреЗ рд╡рд╛рдХреНрдпреЛрдВ рдореЗрдВ рд╕рд╛рдлрд╝ рддреМрд░ рдкрд░ рдмрддрд╛рдУ тАФ рдХреЛрдИ рд▓рдВрдмрд╛ рднрд╛рд╖рдг рдордд рджреЛ



рдЕрдм рддрдХ рдХреА рдмрд╛рддрдЪреАрдд:
{history_text}

Knowledge Base:
{context_text}

рдЕрдм рдЬрд╡рд╛рдм рджреЛ рдпрд╛ рд╕рд╡рд╛рд▓ рдкреВрдЫреЛред
"""
    result = model.generate_content(prompt)
    reply = result.text.strip() if result.text else "рдЙрддреНрддрд░ рдЙрддреНрдкрдиреНрди рдирд╣реАрдВ рд╣реЛ рдкрд╛рдпрд╛ред"
    state["response"] = reply
    state["history"].append({"role": "rep", "text": reply})
    return state

# Graph
chat_graph = StateGraph(ChatbotState)
chat_graph.add_node("initial", initial_node)
chat_graph.add_node("retrieve", retrieve_node)
chat_graph.add_node("generate", generate_node)
chat_graph.set_entry_point("initial")
chat_graph.add_edge("initial", "retrieve")
chat_graph.add_edge("retrieve", "generate")
chat_graph.add_edge("generate", END)
compiled_graph = chat_graph.compile()
